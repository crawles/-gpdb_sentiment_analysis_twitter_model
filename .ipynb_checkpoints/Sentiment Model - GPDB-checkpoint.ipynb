{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T15:53:38.469188",
     "start_time": "2016-09-15T15:53:28.366575"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "\n",
    "import cPickle\n",
    "from dateutil import parser\n",
    "from os import listdir\n",
    "from os.path import isfile, join, split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "import psycopg2\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import df_to_hawq\n",
    "import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T15:53:39.127043",
     "start_time": "2016-09-15T15:53:38.470918"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=params.database,\n",
    "                        host=params.host,\n",
    "                        port=params.port,\n",
    "                        user=params.username,\n",
    "                        password=params.password)\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(params.username,\n",
    "                                                            params.password,\n",
    "                                                            params.host,\n",
    "                                                            params.port,\n",
    "                                                            params.database))\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T15:53:39.169224",
     "start_time": "2016-09-15T15:53:39.128634"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_df = None\n",
    "@register_cell_magic\n",
    "def showsql(line, cell):\n",
    "    \"\"\"\n",
    "        Extract the code in the specific cell (should be valid SQL), and execute\n",
    "        it using the connection object to the backend database. \n",
    "        The resulting Pandas dataframe\n",
    "        is rendered inline below the cell using IPython.display.\n",
    "        You'd use this for SELECT\n",
    "    \"\"\"\n",
    "    #Use the global connection object defined above.\n",
    "    global conn\n",
    "    global _df\n",
    "    _df = psql.read_sql(cell, conn)\n",
    "    conn.commit()\n",
    "    display(_df)\n",
    "    return\n",
    "    \n",
    "@register_cell_magic\n",
    "def execsql(line, cell):\n",
    "    \"\"\"\n",
    "        Extract the code in the specific cell (should be valid SQL), and execute\n",
    "        it using the connection object to the backend database. \n",
    "        You'd use this for CREATE/UPDATE/DELETE\n",
    "    \"\"\"\n",
    "    #Use the global connection object defined above.\n",
    "    global conn\n",
    "    global _df\n",
    "    _df = psql.execute(cell, conn)\n",
    "    conn.commit()\n",
    "    return\n",
    "\n",
    "# We delete these to avoid name conflicts for automagic to work\n",
    "del execsql, showsql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T11:30:12.192846",
     "start_time": "2016-09-14T15:30:06.190Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['polarity', 'tweetid', 'date', 'query_name', 'user', 'text']\n",
    "dftrain = pd.read_csv('stanford-sentiment-twitter-data/training.1600000.processed.noemoticon.csv',\n",
    "                      header = None,\n",
    "                      encoding ='ISO-8859-1')\n",
    "dftest = pd.read_csv('stanford-sentiment-twitter-data/testdata.manual.2009.06.14.csv',\n",
    "                     header = None,\n",
    "                     encoding ='ISO-8859-1')\n",
    "dftrain.columns = columns\n",
    "dftest.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load data to GPDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T09:28:46.943997",
     "start_time": "2016-09-14T09:28:46.915968"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfsubset = dftrain.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T09:28:48.343424",
     "start_time": "2016-09-14T09:28:48.276569"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_to_hawq.df_to_hawq(dfsubset,'mdl.tweets_train',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-14T10:33:50.054575",
     "start_time": "2016-09-14T09:39:38.280612"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dftrain_export = dftrain.copy()\n",
    "dftrain_export['train_set'] = 1\n",
    "dftrain_export = dftrain_export[['polarity','train_set','text']]\n",
    "\n",
    "def df_add_id_train(df,is_train):\n",
    "    df.insert(0,'id',df.index.tolist())\n",
    "    df.insert(1,'is_train',[is_train]*df.shape[0])\n",
    "    return df\n",
    "dftrain_export = df_add_id_train(dftrain_export,1)\n",
    "# _d = dftrain_export.iloc[0:10000,:]\n",
    "# _d.to_sql('tweets_train', engine, schema='mdl', index = False, if_exists = 'replace', chunksize=10000)\n",
    "dftrain_export.to_sql('tweets_train', engine, schema='mdl', index = False, if_exists = 'replace', chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T15:57:02.148698",
     "start_time": "2016-09-15T15:57:01.002205"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%execsql\n",
    "\n",
    "DROP FUNCTION IF EXISTS mdl.train_sentiment_model1(tweets text[], polarities bigint[]);\n",
    "CREATE FUNCTION mdl.train_sentiment_model1(tweets text[], polarities bigint[])\n",
    "RETURNS bytea AS $$\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def regex_preprocess(raw_tweets):\n",
    "    pp_text = pd.Series(raw_tweets)\n",
    "    \n",
    "    user_pat = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)'\n",
    "    http_pat = '(https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,})'\n",
    "    repeat_pat, repeat_repl = \"(.)\\\\1\\\\1+\",'\\\\1\\\\1'\n",
    "\n",
    "    pp_text = pp_text.str.replace(pat = user_pat, repl = 'USERNAME')\n",
    "    pp_text = pp_text.str.replace(pat = http_pat, repl = 'URL')\n",
    "    pp_text.str.replace(pat = repeat_pat, repl = repeat_repl)\n",
    "    return pp_text\n",
    "    \n",
    "sentiment_lr = Pipeline([('count_vect', CountVectorizer(min_df = 100,\n",
    "                                                        ngram_range = (1,1),\n",
    "                                                        stop_words = 'english')), \n",
    "                         ('lr', LogisticRegression())])\n",
    "\n",
    "X = regex_preprocess(tweets)\n",
    "sentiment_lr.fit(X, polarities)\n",
    "return pickle.dumps(sentiment_lr)\n",
    "$$ LANGUAGE plpythonu;\n",
    "\n",
    "DROP TABLE IF EXISTS mdl.sentiment_model;\n",
    "CREATE TABLE mdl.sentiment_model AS\n",
    "SELECT mdl.train_sentiment_model1(array_agg(text),array_agg(polarity)) model\n",
    "FROM\n",
    "(SELECT *\n",
    "FROM mdl.tweets_train\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 1000)f;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T15:59:06.930428",
     "start_time": "2016-09-15T15:59:05.806851"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>apply_sentiment_model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Grrr.. my ipods acting weird too! Jai ho and ...</td>\n",
       "      <td>[0.470217890525, 0.470217890525, 0.60053273936...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  \\\n",
       "0  [Grrr.. my ipods acting weird too! Jai ho and ...   \n",
       "\n",
       "                              apply_sentiment_model1  \n",
       "0  [0.470217890525, 0.470217890525, 0.60053273936...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%showsql\n",
    "SELECT *\n",
    "FROM mdl.sentiment_model;\n",
    "\n",
    "DROP FUNCTION IF EXISTS mdl.apply_sentiment_model1(model bytea, tweets text[]);\n",
    "CREATE FUNCTION mdl.apply_sentiment_model1(model bytea, tweets text[])\n",
    "RETURNS float8[] AS $$\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def regex_preprocess(raw_tweets):\n",
    "    pp_text = pd.Series(raw_tweets)\n",
    "    \n",
    "    user_pat = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)'\n",
    "    http_pat = '(https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,})'\n",
    "    repeat_pat, repeat_repl = \"(.)\\\\1\\\\1+\",'\\\\1\\\\1'\n",
    "\n",
    "    pp_text = pp_text.str.replace(pat = user_pat, repl = 'USERNAME')\n",
    "    pp_text = pp_text.str.replace(pat = http_pat, repl = 'URL')\n",
    "    pp_text.str.replace(pat = repeat_pat, repl = repeat_repl)\n",
    "    return pp_text\n",
    "\n",
    "cl = pickle.loads(model)\n",
    "X = regex_preprocess(tweets)\n",
    "return cl.predict_proba(X)[:,1]\n",
    "$$ LANGUAGE plpythonu;\n",
    "\n",
    "SELECT tweets,mdl.apply_sentiment_model1(model,tweets)\n",
    "FROM\n",
    "    mdl.sentiment_model,\n",
    "    (SELECT array_agg(text) tweets\n",
    "    FROM\n",
    "        (SELECT *\n",
    "        FROM mdl.tweets_train\n",
    "        WHERE random()<.0065\n",
    "        LIMIT 10000\n",
    "        )f\n",
    "    )f1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try model in Python 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T15:59:31.294154",
     "start_time": "2016-09-15T15:59:31.246241"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model\n",
       "0  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o,..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%showsql\n",
    "SELECT model\n",
    "FROM mdl.sentiment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T15:59:46.350369",
     "start_time": "2016-09-15T15:59:46.310133"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "cl = pickle.loads(str(_df.model[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T16:02:16.982108",
     "start_time": "2016-09-15T16:02:16.946354"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    steph curry is a basketball player\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'steph curry is a basketball player'\n",
    "def regex_preprocess(raw_tweets):\n",
    "    pp_text = pd.Series(raw_tweets)\n",
    "    \n",
    "    user_pat = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)'\n",
    "    http_pat = '(https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,})'\n",
    "    repeat_pat, repeat_repl = \"(.)\\\\1\\\\1+\",'\\\\1\\\\1'\n",
    "\n",
    "    pp_text = pp_text.str.replace(pat = user_pat, repl = 'USERNAME')\n",
    "    pp_text = pp_text.str.replace(pat = http_pat, repl = 'URL')\n",
    "    pp_text.str.replace(pat = repeat_pat, repl = repeat_repl)\n",
    "    return pp_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-15T16:02:49.616988",
     "start_time": "2016-09-15T16:02:49.585271"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52978211,  0.47021789],\n",
       "       [ 0.52978211,  0.47021789]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.predict_proba(regex_preprocess(['hello','world']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
